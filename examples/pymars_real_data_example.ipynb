{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pymars Real Data Example: Pima Indians Diabetes Dataset\n",
    "\n",
    "This notebook demonstrates the use of pymars on real health data using the Pima Indians Diabetes dataset. This dataset is commonly used in machine learning for predicting the onset of diabetes based on diagnostic measurements.\n",
    "\n",
    "## Dataset Information\n",
    "\n",
    "The dataset contains 768 observations with the following features:\n",
    "- Number of times pregnant\n",
    "- Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "- Diastolic blood pressure (mm Hg)\n",
    "- Triceps skin fold thickness (mm)\n",
    "- 2-Hour serum insulin (mu U/ml)\n",
    "- Body mass index (weight in kg/(height in m)^2)\n",
    "- Diabetes pedigree function\n",
    "- Age (years)\n",
    "- Class variable (0 or 1)\n",
    "\n",
    "This example demonstrates how pymars can be used for health economic outcomes research, particularly in modeling complex relationships between health indicators and disease outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pymars as earth\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "column_names = [\n",
    "    'pregnancies', 'glucose', 'blood_pressure', 'skin_thickness',\n",
    "    'insulin', 'bmi', 'diabetes_pedigree', 'age', 'outcome'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('pima-indians-diabetes.csv', names=column_names)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(data.head())\n",
    "\n",
    "print(f\"\\nDataset info:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (represented as 0 in this dataset)\n",
    "print(\"Zero values per column (potential missing data):\")\n",
    "zero_counts = (data == 0).sum()\n",
    "print(zero_counts)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Outcome distribution\n",
    "print(f\"\\nOutcome distribution:\")\n",
    "print(data['outcome'].value_counts())\n",
    "print(f\"Percentage with diabetes: {data['outcome'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Distribution of features by outcome\n",
    "features = ['pregnancies', 'glucose', 'blood_pressure', 'skin_thickness', 'insulin', 'bmi', 'diabetes_pedigree', 'age']\n",
    "\n",
    "for i, feature in enumerate(features, 1):\n",
    "    plt.subplot(2, 4, i)\n",
    "    for outcome in [0, 1]:\n",
    "        subset = data[data['outcome'] == outcome][feature]\n",
    "        plt.hist(subset, bins=30, alpha=0.7, label=f'Diabetes: {\"Yes\" if outcome else \"No\"}', density=True)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.title(f'{feature} Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle zero values as missing data (except for pregnancies and outcome)\n",
    "data_processed = data.copy()\n",
    "\n",
    "# Columns where 0 represents missing data\n",
    "cols_with_zeros = ['glucose', 'blood_pressure', 'skin_thickness', 'insulin', 'bmi']\n",
    "\n",
    "# Replace 0s with NaN for these columns\n",
    "for col in cols_with_zeros:\n",
    "    data_processed[col] = data_processed[col].replace(0, np.nan)\n",
    "\n",
    "# Check missing data\n",
    "print(\"Missing data after replacement:\")\n",
    "print(data_processed.isnull().sum())\n",
    "\n",
    "# Separate features and target\n",
    "X = data_processed.drop('outcome', axis=1)\n",
    "y = data_processed['outcome']\n",
    "\n",
    "print(f\"\\nFinal dataset shape: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit MARS Model for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# Fit MARS model for regression (predicting probability)\n",
    "print(\"\\nFitting MARS regression model...\")\n",
    "mars_reg = earth.Earth(\n",
    "    max_degree=2,      # Allow two-way interactions\n",
    "    penalty=3.0,       # GCV penalty\n",
    "    max_terms=21,     # Max number of terms\n",
    "    minspan_alpha=0.05,  # Minimum span control\n",
    "    endspan_alpha=0.05,  # End span control\n",
    "    allow_linear=True,   # Allow linear terms\n",
    "    allow_missing=True,  # Handle missing values\n",
    "    feature_importance_type='gcv'  # Calculate feature importance\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "mars_reg.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Model evaluation\n",
    "train_r2 = mars_reg.score(X_train.values, y_train.values)\n",
    "test_r2 = mars_reg.score(X_test.values, y_test.values)\n",
    "\n",
    "print(f\"\\nMARS Regression Model Summary:\")\n",
    "print(f\"Number of basis functions: {len(mars_reg.basis_) - 1}\")  # Subtract 1 for intercept\n",
    "print(f\"Training R-squared: {train_r2:.3f}\")\n",
    "print(f\"Test R-squared: {test_r2:.3f}\")\n",
    "print(f\"GCV Score: {mars_reg.gcv_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "print(f\"\\nFeature Importances:\")\n",
    "feature_names = list(X.columns)\n",
    "importances = mars_reg.feature_importances_\n",
    "\n",
    "for i, (name, imp) in enumerate(zip(feature_names, importances)):\n",
    "    print(f\"  {name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MARS for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit MARS model for classification\n",
    "print(\"\\nFitting MARS classification model...\")\n",
    "mars_clf = earth.EarthClassifier(\n",
    "    max_degree=2,      # Allow two-way interactions\n",
    "    penalty=3.0,       # GCV penalty\n",
    "    max_terms=21,     # Max number of terms\n",
    "    minspan_alpha=0.05,  # Minimum span control\n",
    "    endspan_alpha=0.05,  # End span control\n",
    "    allow_linear=True,   # Allow linear terms\n",
    "    allow_missing=True   # Handle missing values\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "mars_clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = mars_clf.predict(X_test.values)\n",
    "y_pred_proba = mars_clf.predict_proba(X_test.values)[:, 1]\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = mars_clf.score(X_test.values, y_test.values)\n",
    "auc_score = roc_auc_score(y_test.values, y_pred_proba)\n",
    "\n",
    "print(f\"\\nMARS Classification Model Summary:\")\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"AUC Score: {auc_score:.3f}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_test.values, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test.values, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['No Diabetes', 'Diabetes'],\n",
    "            yticklabels=['No Diabetes', 'Diabetes'])\n",
    "plt.title('Confusion Matrix - MARS Classification')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test.values, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - MARS Classification')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretability and Model Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show selected basis functions\n",
    "print(\"Selected Basis Functions:\")\n",
    "for i, (bf, coef) in enumerate(zip(mars_reg.basis_, mars_reg.coef_)):\n",
    "    if i == 0:  # Intercept\n",
    "        print(f\"  {bf}: {coef:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {bf}: {coef:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate partial dependence plots for top features\n",
    "top_features = np.argsort(importances)[-4:][::-1]\n",
    "fig, axes = earth.plot_partial_dependence(\n",
    "    mars_reg, \n",
    "    X_train.values, \n",
    "    top_features, \n",
    "    feature_names=feature_names, \n",
    "    n_cols=2, \n",
    "    figsize=(12, 10)\n",
    ")\n",
    "plt.suptitle(\"Partial Dependence Plots for Top 4 Features\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with Other Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Impute missing values for other models\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'MARS': mars_clf,\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'SVM': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Fit and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    if name == 'MARS':\n",
    "        # MARS handles missing values internally\n",
    "        model.fit(X_train.values, y_train.values)\n",
    "        y_pred = model.predict(X_test.values)\n",
    "        y_pred_proba = model.predict_proba(X_test.values)[:, 1]\n",
    "    else:\n",
    "        # Other models need imputed data\n",
    "        if name == 'Logistic Regression' or name == 'SVM':\n",
    "            model.fit(X_train_scaled, y_train.values)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        else:\n",
    "            model.fit(X_train_imputed, y_train.values)\n",
    "            y_pred = model.predict(X_test_imputed)\n",
    "            y_pred_proba = model.predict_proba(X_test_imputed)[:, 1]\n",
    "    \n",
    "    accuracy = np.mean(y_pred == y_test.values)\n",
    "    auc = roc_auc_score(y_test.values, y_pred_proba)\n",
    "    results[name] = {'accuracy': accuracy, 'auc': auc}\n",
    "    \n",
    "    print(f\"{name} - Accuracy: {accuracy:.3f}, AUC: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "model_names = list(results.keys())\n",
    "accuracies = [results[name]['accuracy'] for name in model_names]\n",
    "aucs = [results[name]['auc'] for name in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars1 = ax.bar(x - width/2, accuracies, width, label='Accuracy')\n",
    "bars2 = ax.bar(x + width/2, aucs, width, label='AUC')\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.3f}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature importances across models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# MARS feature importance\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.barh(range(len(importances)), importances)\n",
    "plt.yticks(range(len(importances)), feature_names)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('MARS Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Random Forest feature importance\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_imputed, y_train.values)\n",
    "rf_importances = rf_model.feature_importances_\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.barh(range(len(rf_importances)), rf_importances)\n",
    "plt.yticks(range(len(rf_importances)), feature_names)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "# Logistic Regression coefficients\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_scaled, y_train.values)\n",
    "lr_coefs = np.abs(lr_model.coef_[0])\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.barh(range(len(lr_coefs)), lr_coefs)\n",
    "plt.yticks(range(len(lr_coefs)), feature_names)\n",
    "plt.xlabel('|Coefficient|')\n",
    "plt.title('Logistic Regression Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Economics Application Example\n",
    "\n",
    "Let's demonstrate how pymars can be applied to health economics research using this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate healthcare costs based on the diabetes outcome and other factors\n",
    "# This demonstrates how pymars can be used in health economic outcomes research\n",
    "\n",
    "def simulate_healthcare_costs(row):\n",
    "    \"\"\"Simulate healthcare costs based on diabetes status and other health factors\"\"\"\n",
    "    base_cost = 2000  # Base annual healthcare cost\n",
    "    \n",
    "    # Cost associated with diabetes\n",
    "    diabetes_cost = 8000 * row['outcome']  # Extra $8000 for diabetic patients\n",
    "    \n",
    "    # Cost associated with BMI (obesity-related costs)\n",
    "    bmi_cost = 0\n",
    "    if not np.isnan(row['bmi']):\n",
    "        if row['bmi'] >= 30:  # Obese\n",
    "            bmi_cost = 3000\n",
    "        elif row['bmi'] >= 25:  # Overweight\n",
    "            bmi_cost = 1500\n",
    "    \n",
    "    # Cost associated with age\n",
    "    age_cost = 50 * max(0, row['age'] - 40)  # Increasing costs after age 40\n",
    "    \n",
    "    # Cost associated with blood pressure\n",
    "    bp_cost = 0\n",
    "    if not np.isnan(row['blood_pressure']):\n",
    "        if row['blood_pressure'] >= 90:  # Hypertensive\n",
    "            bp_cost = 2000\n",
    "    \n",
    "    # Random variation\n",
    "    random_variation = np.random.normal(0, 1000)\n",
    "    \n",
    "    # Total cost\n",
    "    total_cost = base_cost + diabetes_cost + bmi_cost + age_cost + bp_cost + random_variation\n",
    "    \n",
    "    return max(0, total_cost)  # Ensure non-negative costs\n",
    "\n",
    "# Apply the cost simulation function\n",
    "healthcare_costs = data.apply(simulate_healthcare_costs, axis=1)\n",
    "\n",
    "print(f\"Simulated healthcare costs:\")\n",
    "print(f\"  Mean cost: ${healthcare_costs.mean():,.2f}\")\n",
    "print(f\"  Median cost: ${healthcare_costs.median():,.2f}\")\n",
    "print(f\"  Min cost: ${healthcare_costs.min():,.2f}\")\n",
    "print(f\"  Max cost: ${healthcare_costs.max():,.2f}\")\n",
    "\n",
    "# Compare costs by diabetes status\n",
    "costs_by_diabetes = healthcare_costs.groupby(data['outcome']).describe()\n",
    "print(f\"\\nCosts by diabetes status:\")\n",
    "print(costs_by_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit MARS model to predict healthcare costs\n",
    "print(\"\\nFitting MARS model to predict healthcare costs...\")\n",
    "\n",
    "# Combine original features with the outcome for cost prediction\n",
    "X_cost = data.drop('outcome', axis=1).copy()\n",
    "X_cost['diabetes'] = data['outcome']  # Include diabetes status as a predictor\n",
    "y_cost = healthcare_costs\n",
    "\n",
    "# Split the data\n",
    "X_cost_train, X_cost_test, y_cost_train, y_cost_test = train_test_split(\n",
    "    X_cost, y_cost, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit MARS model for cost prediction\n",
    "mars_cost = earth.Earth(\n",
    "    max_degree=2,      # Allow two-way interactions\n",
    "    penalty=3.0,       # GCV penalty\n",
    "    max_terms=21,     # Max number of terms\n",
    "    minspan_alpha=0.05,  # Minimum span control\n",
    "    endspan_alpha=0.05,  # End span control\n",
    "    allow_linear=True,   # Allow linear terms\n",
    "    allow_missing=True,  # Handle missing values\n",
    "    feature_importance_type='gcv'  # Calculate feature importance\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "mars_cost.fit(X_cost_train.values, y_cost_train.values)\n",
    "\n",
    "# Model evaluation\n",
    "train_r2_cost = mars_cost.score(X_cost_train.values, y_cost_train.values)\n",
    "test_r2_cost = mars_cost.score(X_cost_test.values, y_cost_test.values)\n",
    "\n",
    "print(f\"\\nHealthcare Cost Prediction Model Summary:\")\n",
    "print(f\"Number of basis functions: {len(mars_cost.basis_) - 1}\")  # Subtract 1 for intercept\n",
    "print(f\"Training R-squared: {train_r2_cost:.3f}\")\n",
    "print(f\"Test R-squared: {test_r2_cost:.3f}\")\n",
    "print(f\"GCV Score: {mars_cost.gcv_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for cost prediction\n",
    "cost_feature_names = list(X_cost.columns)\n",
    "cost_importances = mars_cost.feature_importances_\n",
    "\n",
    "print(f\"\\nFeature Importances for Healthcare Cost Prediction:\")\n",
    "for name, imp in zip(cost_feature_names, cost_importances):\n",
    "    print(f\"  {name}: {imp:.4f}\")\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(cost_importances)), cost_importances)\n",
    "plt.yticks(range(len(cost_importances)), cost_feature_names)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for Healthcare Cost Prediction (MARS)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate partial dependence plots for cost prediction\n",
    "top_cost_features = np.argsort(cost_importances)[-4:][::-1]\n",
    "fig, axes = earth.plot_partial_dependence(\n",
    "    mars_cost, \n",
    "    X_cost_train.values, \n",
    "    top_cost_features, \n",
    "    feature_names=cost_feature_names, \n",
    "    n_cols=2, \n",
    "    figsize=(12, 10)\n",
    ")\n",
    "plt.suptitle(\"Partial Dependence Plots for Healthcare Cost Prediction\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This example demonstrates how pymars can be applied to real health data for both clinical prediction and health economics research:\n",
    "\n",
    "1. **Clinical Prediction**: Using MARS to predict diabetes onset based on diagnostic measurements\n",
    "2. **Health Economics**: Using MARS to model healthcare costs based on patient characteristics\n",
    "3. **Interpretability**: Leveraging MARS's explicit basis functions for policy-relevant insights\n",
    "4. **Missing Data Handling**: Demonstrating pymars's ability to handle missing values in health data\n",
    "5. **Non-linear Relationships**: Capturing complex interactions between health factors\n",
    "\n",
    "The Pima Indians Diabetes dataset is an excellent example for showcasing pymars capabilities because it contains:\n",
    "- Multiple continuous variables with potential non-linear relationships\n",
    "- Missing data patterns common in health records\n",
    "- Clear clinical outcomes for prediction\n",
    "- Opportunities for health economic modeling\n",
    "\n",
    "This real-world example demonstrates how pymars can be valuable for health economic outcomes research, where understanding complex relationships between patient characteristics, health outcomes, and costs is crucial for evidence-based policy making."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}