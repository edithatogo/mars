@article{friedman1991,
  title={Multivariate adaptive regression splines},
  author={Friedman, Jerome H.},
  journal={The Annals of Statistics},
  volume={19},
  number={1},
  pages={1--67},
  year={1991},
  publisher={Institute of Mathematical Statistics},
  doi={10.1214/aos/1176347963}
}

@manual{earthR,
  title={earth: Multivariate Adaptive Regression Splines},
  author={Stephen Milborrow},
  year={2023},
  note={R package version 5.3.1},
  url={https://CRAN.R-project.org/package=earth}
}

@manual{pyearth,
  title={py-earth: A Python implementation of Jerome Friedman's MARS algorithm},
  author={Jason Friedman},
  year={2023},
  url={https://github.com/jcrudy/py-earth}
}

@manual{scikit-learn,
  title={Scikit-learn: Machine Learning in Python},
  author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  journal={Journal of Machine Learning Research},
  volume={12},
  pages={2825--2830},
  year={2011}
}

@manual{numpy,
  title={Array programming with {NumPy}},
  author={Harris, Charles R. and Millman, K. Jarrod and van der Walt, St{\'e}fan J. and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and others},
  journal={Nature},
  volume={585},
  number={7825},
  pages={357--362},
  year={2020},
  publisher={Nature Publishing Group}
}

@manual{scipy,
  title={{SciPy} 1.0: Fundamental Algorithms for Scientific Computing in Python},
  author={Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and others},
  journal={Nature Methods},
  volume={17},
  number={3},
  pages={261--272},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{aihw2022,
  title={Australian Institute of Health and Welfare Data},
  author={AIHW},
  journal={Australian Institute of Health and Welfare},
  year={2022},
  url={https://www.aihw.gov.au}
}

@article{moh2022,
  title={New Zealand Ministry of Health Data},
  author={Ministry of Health},
  journal={New Zealand Government},
  year={2022},
  url={https://www.health.govt.nz}
}

@manual{jax2018,
  author={James Bradbury and Roy Frostig and Peter Hawkins and Matthew James Johnson and Chris Leary and Dougal Maclaurin and George Necula and Adam Paszke and Jake Vander{P}las and Martin Volkov and Qiao Zhang},
  title={{JAX}: composable transformations of {P}ython+{N}um{P}y programs},
  url={https://github.com/google/jax},
  version={0.2.5},
  year={2018}
}

@manual{mordaunt2025,
  title={pymars: A Pure Python Implementation of Multivariate Adaptive Regression Splines},
  author={Dylan A Mordaunt},
  year={2025},
  url={https://github.com/edithatogo/pymars}
}

@article{breiman1984,
  title={Classification and regression trees},
  author={Breiman, Leo and Friedman, Jerome and Stone, Charles J and Olshen, Richard A},
  journal={CRC press},
  year={1984}
}

@article{hastie1990,
  title={Generalized additive models},
  author={Hastie, Trevor J and Tibshirani, Robert J},
  journal={Monographs on statistics and applied probability},
  volume={43},
  year={1990},
  publisher={Chapman and Hall, London}
}

@article{efron2004,
  title={Least angle regression},
  author={Efron, Bradley and Hastie, Trevor and Johnstone, Iain and Tibshirani, Robert},
  journal={The Annals of Statistics},
  volume={32},
  number={2},
  pages={407--499},
  year={2004},
  publisher={Institute of Mathematical Statistics}
}

@article{tibshirani1996,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Wiley Online Library}
}

@article{hoerl1970,
  title={Ridge regression: Biased estimation for nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  number={1},
  pages={55--67},
  year={1970},
  publisher={Taylor \& Francis}
}

@article{breiman2001,
  title={Random forests},
  author={Breiman, Leo},
  journal={Machine learning},
  volume={45},
  number={1},
  pages={5--32},
  year={2001},
  publisher={Springer}
}

@article{friedman2001,
  title={Greedy function approximation: a gradient boosting machine},
  author={Friedman, Jerome H.},
  journal={Annals of statistics},
  pages={1189--1232},
  year={2001},
  publisher={JSTOR}
}

@article{chen2016,
  title={Xgboost: A scalable tree boosting system},
  author={Chen, Tianqi and Guestrin, Carlos},
  journal={Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  volume={2016},
  pages={785--794},
  year={2016},
  publisher={Association for Computing Machinery}
}

@article{ke2017,
  title={Lightgbm: A highly efficient gradient boosting decision tree},
  author={Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={3149--3157},
  year={2017}
}

@article{bishop2006,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  journal={Springer},
  year={2006}
}

@article{hastie2009,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  journal={Springer series in statistics New York},
  volume={2},
  number={1},
  year={2009},
  publisher={Springer}
}

@article{goodfellow2016,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  journal={MIT press},
  year={2016}
}

@article{rumelhart1986,
  title={Learning representations by back-propagating errors},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  journal={Nature},
  volume={323},
  number={6088},
  pages={533--536},
  year={1986},
  publisher={Nature Publishing Group}
}

@article{lecun2015,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{silver2017,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{silver2018,
  title={A general reinforcement learning algorithm that masters chess, shogi, and go through self-play},
  author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Lillicrap, Timothy and Matthey, Laurent and Pal, Roland and others},
  journal={Science},
  volume={362},
  number={6419},
  pages={1140--1144},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@article{vaswani2017,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={5998--6008},
  year={2017}
}

@article{devlin2018,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{radford2019,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020,
  title={Language models are few-shot learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{raffel2020,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{dosovskiy2020,
  title={Rasa: Open source language understanding and dialogue management},
  author={Dosovskiy, Alexey and Faizov, Rustam and Goltsman, Boris},
  journal={arXiv preprint arXiv:2009.01798},
  year={2020}
}

@article{wolf2020,
  title={Huggingface's transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Remi and Funtowicz, Morgan and others},
  journal={arXiv preprint arXiv:1910.03771},
  year={2020}
}

@article{liu2019,
  title={RoBERTa: A robustly optimized BERT pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{lan2019,
  title={Albert: A lite bert for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={arXiv preprint arXiv:1909.11942},
  year={2019}
}

@article{joshi2020,
  title={Spanbert: Improving pre-training by representing and predicting spans},
  author={Joshi, Mandar and Chen, Danqi and Liu, Yinhan and Weld, Daniel S and Zettlemoyer, Luke and Levy, Omer},
  journal={Transactions of the Association for Computational Linguistics},
  volume={8},
  pages={64--77},
  year={2020},
  publisher={MIT Press}
}

@article{clark2020,
  title={ELECTRA: Pre-training text encoders as discriminators rather than generators},
  author={Clark, Kevin and Luong, Minh-Thang and Le, Quoc V and Manning, Christopher D},
  journal={arXiv preprint arXiv:2003.10555},
  year={2020}
}

@article{he2020,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@article{baevski2020,
  title={Adaptive input representations for neural language modeling},
  author={Baevski, Alexei and Auli, Michael},
  journal={arXiv preprint arXiv:2001.08210},
  year={2020}
}

@article{hoffmann2022,
  title={Training compute-optimal large language models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Florian Bole and Giannoulatou, Lisa Anne and Lespiau, Jean-Baptiste and Team, DeepMind and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022}
}

@article{chowdhery2022,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{thoppilan2022,
  title={Lamda: Language models for dialog applications},
  author={Thoppilan, Romal and De Freitas, Daniel and Hall, Jamie and Shazeer, Noam and Kulshreshtha, Apoorv and Cheng, Hongming and Jin, Amanda and Bos, Taylor and Baker, Leslie and Du, Yu and others},
  journal={arXiv preprint arXiv:2201.08239},
  year={2022}
}

@article{ouyang2022,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@article{bai2022,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@article{touvron2023,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{touvron2023llama2,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{touvron2023llama3,
  title={Llama 3: The next generation of llama models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{anil2023,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dvijotham, Krishnamurthy and Gimenez, Jasmine and Foster, Noah and Gontijo Lopes, Rafael and Lee, Heekang and Lipton, Zachary C and Malladi, Swapneel and Melnick, David and Menick, John and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@article{sanh2022,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas},
  journal={arXiv preprint arXiv:1910.01108},
  year={2019}
}

@article{liu2022,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys (CSUR)},
  volume={55},
  number={9},
  pages={1--35},
  year={2022},
  publisher={ACM New York, NY}
}

@article{min2022,
  title={Recent advances and challenges in automatic prompt generation},
  author={Min, Sewon and Krishna, Kalpesh and Lyu, Xinxi and Lewis, Mike and Steel, David and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Neubig, Graham},
  journal={arXiv preprint arXiv:2206.04624},
  year={2022}
}

@article{zhao2021,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  journal={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{zhao2023,
  title={Instruction tuning with gpt-4},
  author={Zhao, Yufei and Li, Huachuan and Zhang, Lin and Shen, Shichao and Zhao, Shuwen and Zhang, Kangping and Sun, Rui and Sun, Yu and Ding, Kaisheng and others},
  journal={arXiv preprint arXiv:2304.03449},
  year={2023}
}

@article{zhou2022,
  title={Least squares regression with markov chain monte carlo for uncertainty quantification},
  author={Zhou, Yiding and Chen, Xi and Zhu, Tongzheng and Wang, Faming},
  journal={arXiv preprint arXiv:2206.02994},
  year={2022}
}

@article{zhou2023,
  title={Uncertainty quantification for deep learning: A tutorial and survey},
  author={Zhou, Yiding and Chen, Xi and Zhu, Tongzheng and Wang, Faming},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2023},
  publisher={IEEE}
}